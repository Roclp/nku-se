# 操作系统

2020最新南开大学期末最全知识点总结，吐血整理，包上90分！里面有短期调度器，进程行为，Cpu密集型&IO密集型，抢占式，非抢占式，先来先服务（FIFO），抢占式的最短剩余时间优先，轮转调度，优先级调度，多级队列调度，内核级线程，用户级线程，死锁，死锁检测&死锁恢复，银行家算法，基址寄存器&界限寄存器，虚拟内存，MUU（内存管理单元），硬件TLB，页面置换算法，软件实现LRU，工作集时钟页面置换算法，文件系统， 必考：程序控制ｉ／ｏ，电梯算法！！！考





填空

一堆简答 

为什么分两种状态

进程几种状态

系统调用

Linux内核（上机）

文件包括哪几部分 文件控制块





系统调用

名词解释



并发共享虚拟异步

库函数



进程线程 差异 比较

调度算法

IPC

死锁

进程控制块PCB



**用户级**线程和内核级线程 怎么实现，区别



多进程到多线程	库函数为什么需要改，有什么区别



哲学家 读写者 **理发师**



死锁必要条件 解决方案 银行家算法



基本存在管理的特点： 连续的一次性载入

虚拟存储：局部性



balady



文件系统

fat表原理 i节点原理计算 二选一



空闲块管理：成组链接法



磁盘调度



i/o控制方式



假脱机技术 原理 例子



未来发展方向

多核 虚拟化











中断和陷阱的区别：

中断：与当前执行程序无关

陷阱traps：当前执行的程序异常中断



## 计算机系统概述

### 操作系统：

- 最基本的系统软件
- 系统资源管理者（控制）
  - **文件管理、内存管理、处理机（CPU）管理、硬件设备管理（摄像头、打印机）**
- 用户和计算机硬件的接口
- 四个特征
  - 并发：宏观同时，微观交替
  - 共享：资源共享（分时共享）
  - 虚拟：
  - 异步：并发执行，

### 运行机制和体系结构：

- 两种指令
  - 特权指令：如内存清零指令  （禁止用户程序使用）
  - 非特权指令：如运算指令  （用户程序使用的指令）

- CPU处理器的两种状态（状态寄存器PSW的标识位）
  - 用户态：此时CPU只能执行非特权指令
  - 核心态：特权指令、非特权指令都课执行
- 两种程序
  - 应用程序（用户程序）：非特权指令 用户态
  - 内核程序：内核程序是系统的的管理者 特权指令、非特权指令 核心态

### 中断和异常：

意外——主机干预——暂停原程序——中断服务程序——返回原程序

中断发生后，CPU立即进入核心态

要想实现“用户态——核心态”，必须经过中断，执行特权指令，将PSW的标志位设置为“用户态”

- 两种中断类型
  - 内中断：

![image-20231027113644384](C:/Users/LX/AppData/Roaming/Typora/typora-user-images/image-20231027113644384.png)

### 系统调用：

操作系统提供给应用程序（编程人员）调用请求使用操作系统内核服务的接口。

- 系统调用发生在用户态，对系统调用的处理发生在核心态。
- 执行陷入指令（自陷指令或访管指令）会处理内中断，使处理器（CPU）从用户态进入核心态。



## 进程管理

进程：运行着的程序。

**PCB是进程存在的唯一标识。**

**进程控制就是要实现进程状态转换。**原语——核心态

**进程通信就是进程之间的信息交换**

![image-20210804135200848](https://s2.loli.net/2023/11/03/n3Q98iHpPvNLVFf.png)



### 线程概念和多线程模型

- 概念
  - 线程可以理解为轻量级的进程
  - 线程是一个基本的CPU执行单元，也是程序执行流的最小单位
  - 引入线程后，进程作为除CPU之外的系统资源的分配单元

- 用户级线程
  - 用户态 无需操作系统干预
- 内核级线程
  - 操作系统内核完成
- 多对一模型
  - 多个用户级线程映射到一个内核级线程（每个用户级进程只对应一个内核级线程）
  - 优点:用户级线程的切换在用户空间即可完成，不需要切换到核心态，**线程管理的系统开销小，效率高**
  - 缺点:当一个用户级线程被阻塞后，整个进程都会被阻塞，并发度不高。**多个线程不可在多核处理机上并行运行**

- 一对一模型
  - 一个用户级线程映射到一个内核级线程
  - 优点:当一个线程被阻塞后，别的线程还可以继续执行，并发能力强。**多线程可在多核处理机上并行执行。**
  - 缺点:一个用户进程会占用多个内核级线程，线程切换由操作系统内核完成，需要切换到核心态，**因此线程管理的成本高，开销大。**

- 多对多模型
  - 多对多模型:n用户级线程映射到m个内核级线程(n >=m)。每个用户进程对应m个内核级线程。
  - 克服了多对一模型并发度不高的缺点，又克服了一对一模型中一个用户进程占用太多内核级线程，开销太大的缺点。

### 处理机调度的概念和层次：









### 调度算法

- ##### 先来先服务（FCFS，First Come First Serve）

![image-20210805144150920](https://s2.loli.net/2023/11/17/X5Ph1kzKDjL28ao.png)

- ##### 短作业优先（SJF，Shortest Job First）

![image-20210805145121363](https://s2.loli.net/2023/11/17/4gyMCNRUGuvo72x.png)

- ##### 时间片轮转调度（RR，Round-Robin）

  ![image-20210805151053159](https://s2.loli.net/2023/11/17/OIsgdtNoiKWGHYr.png)

- ##### 优先级调度算法

![image-20210805152056532](https://s2.loli.net/2023/11/17/A4y1YjFE35pmoel.png)

- ##### 多级反馈队列调度算法

![image-20210805152958697](https://s2.loli.net/2023/11/17/wRPJgEWsixKq3fQ.png)







### 进程同步与进程互斥

- 同步
  - 按顺序执行
  - 异步：顺序不确定
- 互斥
  - 临界资源互斥访问
    - 空闲让进（临界区空闲，请求则允许访问）
    - 忙则等待（临界区忙，阻塞等待）
    - 有限等待（阻塞等待时间的有限，避免饥饿）（受惠的是进程自己）
    - 让权等待（当进程不能进入临界区时，应立即释放处理机，避免忙等待）（受惠的是其他进程）



### 进程互斥的软件实现方法

#### 单标志法

算法思想：每个进程在访问完临界区后会把使用临界区的权限转交给另一个进程。也就是说**每个进程进入临界区的权限只能被另一个进程赋予**。

![image-20210805155502678](https://s2.loli.net/2023/11/03/vHAhmXw7b2xFf4C.png)

单标志法可以实现**“同一时刻最多只允许一个进程访问临界区”**，但违背**“空闲让进”**原则。



#### 双标志先检查法







### 信号量机制

- 信号量机制实现进程互斥

  - 划定临界区（如：对临界资源打印机的访问就应放在临界区)
  - 设置互斥信号量mutex，初值为1
  - 在临界区之前执行P(mutex) wait
  - 在临界区之后执行V(mutex) signal
  
- 信号量机制实现进程同步

  进程同步：要让各并发进程按要求有序的进行。

  - 分析什么地方需要实现“同步关系”，即必须保证“一前一后”执行的两个操作（或两句代码)
  - 设置同步信号量s,初始为0
  - 在“前操作”之后执行v(S)
  - 在“后操作”之前执行P(S)



### 生产者——消费者问题





### 吸烟者问题



### 读者——写者问题



### 哲学家吃饭问题





### 死锁 deadlock

- 含义
  - 在并发环境下，各进程因竞争资源而造成的一种互相等待对方手里的资源，导致各进程都阻塞，都无法向前推进的现象，就是“死锁“。

- 死锁，饥饿，死循环的区别

  - **死锁：**互相等待对方手里的资源，导致阻塞，无法正常向前推进
  - **饥饿：**长期得不到想要的资源，无法正常向前推进。比如：SPF算法中长进程可能一直得不到处理，发生“饥饿”
  - **死循环：**程序逻辑bug

- 死锁的必要条件（同时满足4个条件）

  - **互斥：**必须互斥使用的资源（哲学家的筷子、打印机设备）

  - **不剥夺：**互斥资源没有使用完，只能主动释放，其他进程不能夺走

  - **请求和保持：**已经拥有至少一个互斥资源，但又有新的互斥资源请求，该资源又被其他进程占有，此时请求进程被阻塞，但又对自己已经拥有的资源保持占有

  - **循环等待：**资源的循环等待链，每一个进程拥有的资源被另一个进程请求

  注意：死锁一定有循环等待，循环等待未必死锁（同类资源数大于1）

- 什么时候会发生死锁

  - 对不可剥夺的互斥资源的竞争

  - 进程推进顺序非法

  - 信号量使用不当

- 死锁的处理策略

  - 预防死锁：破坏四个条件之一
    - 互斥：假脱机（虚拟）
    - 不剥夺：抢占式
    - 请求和保持：一次性请求分配所需的所有资源
    - 循环等待：资源编号，按序访问
  - 避免死锁：**安全序列**（安全状态一定不会死锁） A R C E **银行家算法**   **资源分配图**
  - 检测和恢复：发生死锁后采取某种措施解除死锁
    - 资源剥夺法
    - 终止进程法
    - 回退进程法



## 内存管理

内存是用于存放数据的硬件。程序执行前需要先放到内存中才能被CPU处理。

- 内存保护的两种方法
  - 在CPU中设置一对上、下限寄存器，存放进程的上、下限地址。进程的指令要访问某个地址时，CPU检查是否越界。
  - 采用重定位寄存器（又称基址寄存器）和界地址寄存器（又称限长寄存器）进行越界检查。重定位寄存器中存放的是进程的起始物理地址。界地址寄存器中存放的是进程的最大逻辑地址。



### 连续分配管理方式

连续分配：为用户进程分配的必须是一个连续的内存空间。

**分区**

- ##### 固定分区分配![image-20210808153255068](https://img-blog.csdnimg.cn/img_convert/a5549d30aa3ec597fe0f0770b441d046.png)

![image-20210808153337606](https://img-blog.csdnimg.cn/img_convert/0b4097c2a3f3c66b33767dbf49546bfd.png)

- ##### 动态分区分配（可变分区分配）

  - 根据进程的大小动态地建立分区，并使分区的大小正好适合进程的需要。因此系统分区的大小和数目是可变的。

- #####  动态分区分配算法

  - 首次适应算法 First Fit
    - 每次都从低地址开始查找，找到第一个能满足大小的空闲分区。
  - 临近适应算法 Next Fit
    - 首次适应算法每次都从链头开始查找的。这可能会导致低地址部分出现很多小的空闲分区，而每次分配查找时，都要经过这些分区，因此也增加了查找的开销。**如果每次都从上次查找结束的位置开始检索，就能解决上述问题。**
  - 最差（大）适应算法 Worst/Largest Fit
    - 为了解决最佳适应算法的问题――即留下太多难以利用的小碎片，可以在**每次分配时优先使用最大的连续空闲区**，这样分配后剩余的空闲区就不会太小，更方便使用。
  - 最佳适应算法 Best Fit
    - 由于动态分区分配是一种连续分配方式，为各进程分配的空间必须是连续的一整片区域。因此为了保证当“大进程”到来时能有连续的大片空间，可以尽可能多地留下大片的空闲区，即，**优先使用更小的空闲区**。
      - 碎片
        - 内部碎片，分配给某进程的内存区域中，如果有些部分没有用上。
          外部碎片，是指内存中的某些空闲分区由于太小而难以利用。
        - 动态分区分配没有内部碎片，但是有外部碎片。
        - 如果内存中空闲空间的总和本来可以满足某进程的要求，但由于进程需要的是一整块连续的内存空间，因此这些
          进程“碎片”不能满足进程的需求。可以通过紧凑（(拼凑，Compaction)技术来解决外部碎片。
  - 快速适应算法
  - 买鞋

![image-20210808160008902](https://s2.loli.net/2023/11/17/6DfavBwC4mVApcE.png)



### 分页/分段存储

**基本分页存储管理的思想――把内存分为一个个相等的小分区,再按照分区大小把进程拆分成一个个小部分。**

**各个页面不必连续存放，也不必按先后顺序来，可以放到不相邻的各个页框中。**



具有快表的地址变换机构
1.局部性原理
时间局部性:如果执行了程序中的某条指令，那么不久后这条指令很有可能再次执行;如果某个数据被访问过，不久之后该数据很可能再次被访问。(因为程序中存在大量的循环)
空间局部性:一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也很有可能被访问。(因为很多数据在内存中都是连续存放的)

上小节介绍的基本地址变换机构中，每次要访问一个逻辑地址，都需要查询内存中的页表。由于局部性原理，可能连续很多次查到的都是同一个页表项。既然如此，能否利用这个特性减少访问页表的次数呢?

2.快表
快表，又称联想寄存器（TLB），是一种访问速度比内存快很多的高速缓冲存储器，用来存放当前访问的若干页表项，以加速地址变换的过程。与此对应，内存中的页表常称为慢表。



多级页表：

- 第一次访存:访问内存中的页目录表
- 第二次访存:访问内存中的二级页表
- 第三次访存:访问目标内存单元

N级页表访问一个逻辑地址需要N+1次访问内存。



4.分段，分页对比
页是信息的物理单位。分页的主要目的是为了实现离散分配，提高内存利用率。分页仅仅是系统管理上的需要，完全是系统行为，对用户是不可见的。
段是信息的逻辑单位。分段的主要目的是更好地满足用户需求。一个段通常包含着一组属于一个逻辑模块的信息。分段对用户是可见的，用户编程时需要显式地给出段名。
页的大小固定且由系统决定。段的长度却不固定，决定于用户编写的程序。
分页的用户进程地址空间是一维的，程序员只需给出一个记忆符即可表示一个地址。
分段的用户进程地址空间是二维的，程序员在标识一个地址时，既要给出段名，也要给出段内地址。
分段比分页更容易实现信息的共享和保护。







### 虚拟内存



















### 请求分页管理

























### 页面置换算法



LRU

FIFO

Belady异常——当为进程分配的物理块数增大时，缺页次数不减反增的异常现象。

**只有FIFO算法会产生Belady异常**。另外，FIFO算法虽然实现简单，但是该算法与进程实际运行时的规律不适应，因为先进入的页面也有可能最经常被访问。因此，**算法性能差。**



**抖动**

- 原因
  - 多进程   全局页面置换
  - 操作系统监控CPU利用率

刚刚换出的页面马上又要换入内存，刚刚换入的页面马上又要换出外存，这种频繁的页面调度行为称为抖动，或颠簸。产生抖动的主要原因是进程频繁访问的页面数目高于可用的物理块数（分配给进程的物理块不够)。

为进程分配的物理块太少，会使进程发生抖动现象。为进程分配的物理块太多，又会降低系统整体的并发度，降低某些资源的利用率

工作集时钟页面置换算法：

驻留集:指请求分页存储管理中给进程分配的内存块的集合。

工作集:指在某段时间间隔里，进程实际访问页面的集合。（LRU）

一般来说，驻留集大小不能小于工作集大小，否则进程运行过程中将频繁缺页。
![image-20210809165818657](https://s2.loli.net/2023/12/08/EAdOWvHwcFJBG3b.png)





局部置换：发生缺页时只能选进程自己的物理块进行置换（进程内部置换）。

全局置换：可以将操作系统保留的空闲物理块分配给缺页进程，也可以将别的进程持有的物理块置换到外存，再分配给缺页进程。

 



## 文件系统



文件——信息的逻辑单元 字节流



**混合索引（I node）**

**成组连接法 原理**





## I/O管理



### 中断和陷阱的区别：

中断：与当前执行程序无关

陷阱traps：当前执行的程序异常中断



### I/O控制方式

- ##### 程序直接控制

  - CPU发出I/O指令后需要不断轮询（忙等待）

- **中断驱动**

  - CPU发出I/O命令后可以做其他事，I/O完成后向CPU发出中断信号

- **DMA直接内存访问**
  - CPU发出I/O命令后可以做其他事，I/O完成后向CPU发出中断信号
  - 每次访存能够连续读取多个字（块）（降低CPU干预频率）
  - 一个连续块
- **通道控制**
  - 通道控制方式是为了解决DMA方式连续存储的问题
  - 多个连续块



buffer





磁盘

**柱面号，盘面号，扇区号**

FCFS

SSF

Elevater(SCAN)



![image-20231229101248465](https://s2.loli.net/2023/12/29/85BpFqJ24sAYtOR.png)
